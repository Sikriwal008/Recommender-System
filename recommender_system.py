# -*- coding: utf-8 -*-
"""Recommender_system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rhp8D1lUCD4A3H-K69p0ryvE0iHV7pGf
"""

import numpy as np
import pandas as pd

movies=pd.read_csv('/content/drive/MyDrive/CampusX project/Recomender System/tmdb_5000_movies.csv')
credits=pd.read_csv('/content/drive/MyDrive/CampusX project/Recomender System/tmdb_5000_credits.csv')

movies.head()

movies.shape

credits.head()

credits.shape

movies=movies.merge(credits, how='inner')

movies.info()

#feature selection
movies=movies[['genres','id','keywords','overview','title','cast','crew']]
movies.head()

#cheaking for missing values
movies.isnull().sum()

movies.shape

#removing rows with missing rows
movies.dropna(inplace=True)
movies.shape

#checking for duplicate data
movies.duplicated().sum()

movies.genres[0]

import ast
def convert(obj):
  l=[]
  for i in ast.literal_eval(obj):
    l.append(i['name'])
  return l

movies['genres']=movies['genres'].apply(convert)
movies.head()

movies.keywords[0]

ast.literal_eval(movies.keywords[0])

def convert2(obj):
  l=[]
  for i in ast.literal_eval(obj):
    l.append(i['name'])
  return l

movies['keywords']=movies['keywords'].apply(convert2)
movies.head()

movies.cast[0]

ast.literal_eval(movies.cast[0])

def convert3(obj):
  l=[]
  j=0
  for i in ast.literal_eval(obj):
    if j<3:
      l.append(i['name'])
      j=j+1
  return l

movies['cast']=movies['cast'].apply(convert3)
movies.head()

movies.crew[0]

ast.literal_eval(movies.crew[0])

def convert4(obj):
  l=[]
  for i in ast.literal_eval(obj):
    if (i['job']=='Director'):
      l.append(i['name'])
  return l

movies['crew']=movies['crew'].apply(convert4)
movies.head()

movies['overview'][0]

movies['genres'][0]

movies['overview']=movies['overview'].apply(lambda x:x.split())
movies.head()

movies['genres']=movies['genres'].apply(lambda x:[i.replace(" ","") for i in x])
movies['keywords']=movies['keywords'].apply(lambda x:[i.replace(" ","") for i in x])
movies['cast']=movies['cast'].apply(lambda x:[i.replace(" ","") for i in x])
movies['crew']=movies['crew'].apply(lambda x:[i.replace(" ","") for i in x])
movies.head()

movies['tags']=movies['overview']+movies['genres']+movies['keywords']+movies['cast']+movies['crew']
movies.head()

movies=movies[['title','id','tags']]
movies.head()

#converting list to string
movies['tags']=movies['tags'].apply(lambda x:" ".join(x))
movies.head()

movies.tags[0]

movies['tags']=movies['tags'].apply(lambda x:x.lower())
movies.head()

movies['tags'][0]

movies['tags'][1]

"""TEST VECORIZATION BY USING  BAGS OF WORDS
DEFINITION:
Text vectorization is the process of converting textual data into numerical vectors. In natural language processing (NLP), text vectorization is a crucial step because most machine learning algorithms require numerical input. Text vectorization allows computers to understand and analyze textual data by representing words, phrases, or documents as numerical vectors in a high-dimensional space

BAGS OF WORDS:IN THIS WE COMBINE ALL TAGS OF ALL MOVIES AND THEN FIND 5000 MOST FREQUENTLY USED WORDS AND THEN WE FIND THE FREQUENCY OF EACH WORDS IN EACH MOVIES AND THIS PROCESS FORM A MATRIX OF 5000 * 5000 DIMENSION AND EACH DIMENSIUON CONTAINS 5000 VECTORS.FROM NOW WE TAKE A MOVIE NAME AND RECOMMENDS 5 SIMILAR MOVIES NAME THAT HAVE THE CLOSEST VECTOR



"""

from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(max_features=5000,stop_words='english') #note:max_feature gives how many most frequent  words to be taken and stop word removes all the words which are mainly
                                                          # used for sentence formation but have no meaning

vectors=cv.fit_transform(movies['tags']).toarray()
vectors

vectors[0]

arr=cv.get_feature_names_out()
print(arr)

"""Now we will apply Steaming:
"stemming," which is a text preprocessing technique in natural language processing (NLP). Stemming is the process of reducing words to their root or base form, called the "stem," by removing suffixes or prefixes. The goal of stemming is to normalize words so that variations of the same word are treated as identical, thereby reducing the vocabulary size and improving computational efficiency.

For example, the words "running," "runs," and "runner" would all be stemmed to the base form "run."

"""

#STEMMING
import nltk #its a natural language processing library
from nltk.stem import PorterStemmer
# Instantiate the PorterStemmer object
ps = PorterStemmer()

def stem(text):
  y=[]
  for i in text.split():#converting string to list
    y.append(ps.stem(i))

  return " ".join(y) #here we are converting a list to string

ps.stem('loving')

ps.stem('dancing')

movies['tags'].apply(stem)

arr=cv.get_feature_names_out()
print(arr)

"""Distance(cosine) calculatin:Cosine similarity is a measure used to determine how similar two vectors are in a high-dimensional space. It calculates the cosine of the angle between two vectors, where a smaller angle indicates higher similarity and a larger angle indicates lower similarity. Cosine similarity is often used in text mining and information retrieval to compare the similarity between documents or the similarity between words based on their vector representations

Note:for hi dimensional data eucledian distance cannot be used
"""

from sklearn.metrics.pairwise import cosine_similarity
similarity=cosine_similarity(vectors)
similarity # here similarity matrix gives the similarity of each movie with respect to each movie
           #if similarity near to one very much similar and near to 0 said very leass similatr

similarity[0]

sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])[1:6]#in this line we are using enemurate function to hold the index of movie and their similarity
                                                                          #conver enemurate to list and then sord the list in descending order of similarity and gives 5 similar movies

def recommend(movie):
  movie_index=movies[movies['title']==movie].index[0]#fetching the row number of that movie
  distance=similarity[movie_index]
  movie_list=sorted(list(enumerate(distance)),reverse=True,key=lambda x:x[1])[1:6]
  for i in movie_list:
    print(movies.iloc[i[0]].title)

recommend('Batman Begins')

import pickle

pickle.dump(movies.to_dict(),open('movies_dict.pkl','wb'))
pickle.dump(similarity,open('similarity.pkl','wb'))